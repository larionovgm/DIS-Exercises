{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 8: Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libaries needed: pandas, sklearn>=0.19, numpy, nltk, graphviz (python-graphviz), e.g.**\n",
    "```\n",
    "conda install graphviz\n",
    "conda install python-graphviz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure your environment is setup with the right libraries. In this exercise, you should be filling the empty code sections, marked as `TODO:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8f5a919f03fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analyzing Weather Sentiments in Tweets\n",
    "\n",
    "In this exercise, we consider the [Weather sentiment](https://data.world/crowdflower/weather-sentiment) dataset from [Crowdflower](https://www.crowdflower.com/).\n",
    "\n",
    "To create this dataset, contributors were asked to grade the sentiment of a particular tweet relating to the weather. Contributors could choose among the following categories:\n",
    "1. Positive\n",
    "2. Negative\n",
    "3. I can't tell\n",
    "4. Neutral / author is just sharing information\n",
    "5. Tweet not related to weather condition\n",
    "\n",
    "The catch is that 20 contributors graded each tweet. Thus, in many cases contributors assigned conflicting sentiment labels to the same tweet. \n",
    "\n",
    "In the `data` directory, you will find the file [weather-non-agg-DFE.csv](data/weather-non-agg-DFE.csv) containing the raw contributor answers for each of the 1,000 tweets.\n",
    "\n",
    "\n",
    "The fields of the csv file are as follows:\n",
    "1. **_unit\\_id_**: CrowdFlower’s numeric ID for the unit,\n",
    "2. **channel**: channel via which the contributor entered the job,\n",
    "3. **trust**: the contributor's accuracy level in the current job, determined by their accuracy on the Test Questions they’ve seen in the job,\n",
    "4. **worker_id**: CrowdFlower Contributor ID,\n",
    "5. **country**: worker's country code\n",
    "6. **region**: worker's region\n",
    "7. **city**: worker's city\n",
    "8. **emotion**: worker's assigned emotion to the tweet\n",
    "9. **tweet_id**: id of the tweet\n",
    "10. **tweet_body**: body text of the tweet\n",
    "\n",
    "\n",
    "Our goal in this exercise is to build a classifier that predicts the tweet's emotion according to the aforementioned categories. Towards that, we will be first aggregating the results of the crowdflower task in order to get a clean dataset. Then we will be preparing the data features by tokenizing the text. Finally, we will be inputting these features into a text classifier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 1: Data Formatting\n",
    "\n",
    "To begin with let's load the data into a format we can work with.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id_</th>\n",
       "      <th>channel</th>\n",
       "      <th>trust</th>\n",
       "      <th>worker_id</th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>emotion</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>314960382</td>\n",
       "      <td>clixsense</td>\n",
       "      <td>0.4541</td>\n",
       "      <td>18034918</td>\n",
       "      <td>IND</td>\n",
       "      <td>7</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Neutral / author is just sharing information</td>\n",
       "      <td>82846118</td>\n",
       "      <td>Fire Weather Watch issued May 17 at 4:21PM CDT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>314960385</td>\n",
       "      <td>clixsense</td>\n",
       "      <td>0.4541</td>\n",
       "      <td>18034918</td>\n",
       "      <td>IND</td>\n",
       "      <td>7</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>82510997</td>\n",
       "      <td>Passing out now.  working tonight. Storms toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314960391</td>\n",
       "      <td>clixsense</td>\n",
       "      <td>0.4541</td>\n",
       "      <td>18034918</td>\n",
       "      <td>IND</td>\n",
       "      <td>7</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Negative</td>\n",
       "      <td>83271279</td>\n",
       "      <td>RT @mention: \"The storm is only that which aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>314960396</td>\n",
       "      <td>clixsense</td>\n",
       "      <td>0.4541</td>\n",
       "      <td>18034918</td>\n",
       "      <td>IND</td>\n",
       "      <td>7</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Positive</td>\n",
       "      <td>80058872</td>\n",
       "      <td>It is hot out here but it feels great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314960400</td>\n",
       "      <td>clixsense</td>\n",
       "      <td>0.4541</td>\n",
       "      <td>18034918</td>\n",
       "      <td>IND</td>\n",
       "      <td>7</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Neutral / author is just sharing information</td>\n",
       "      <td>80058809</td>\n",
       "      <td>I can't find a way to delete my iWitness Weath...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _unit_id_    channel   trust  worker_id country region   city  \\\n",
       "0  314960382  clixsense  0.4541   18034918     IND      7  Delhi   \n",
       "1  314960385  clixsense  0.4541   18034918     IND      7  Delhi   \n",
       "2  314960391  clixsense  0.4541   18034918     IND      7  Delhi   \n",
       "3  314960396  clixsense  0.4541   18034918     IND      7  Delhi   \n",
       "4  314960400  clixsense  0.4541   18034918     IND      7  Delhi   \n",
       "\n",
       "                                        emotion  tweet_id  \\\n",
       "0  Neutral / author is just sharing information  82846118   \n",
       "1                                      Positive  82510997   \n",
       "2                                      Negative  83271279   \n",
       "3                                      Positive  80058872   \n",
       "4  Neutral / author is just sharing information  80058809   \n",
       "\n",
       "                                          tweet_body  \n",
       "0  Fire Weather Watch issued May 17 at 4:21PM CDT...  \n",
       "1  Passing out now.  working tonight. Storms toda...  \n",
       "2  RT @mention: \"The storm is only that which aut...  \n",
       "3              It is hot out here but it feels great  \n",
       "4  I can't find a way to delete my iWitness Weath...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/weather-non-agg-DFE.csv')\n",
    "# print the shape of our data frame\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our labels are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all tweets:\n",
      "Neutral / author is just sharing information    5371\n",
      "Negative                                        4986\n",
      "Positive                                        4953\n",
      "Tweet not related to weather condition          3553\n",
      "I can't tell                                    1137\n",
      "Name: emotion, dtype: int64\n",
      "For tweet_id=82846118:\n",
      "Neutral / author is just sharing information    16\n",
      "Positive                                         1\n",
      "Tweet not related to weather condition           1\n",
      "I can't tell                                     1\n",
      "Negative                                         1\n",
      "Name: emotion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"For all tweets:\\n\" + str(data.emotion.value_counts()))\n",
    "print(\"For tweet_id=82846118:\\n\" + str(data[data.tweet_id==82846118].emotion.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 2: Aggregating the Annotations\n",
    "\n",
    "Now we will be aggregating the data of the workers to obtain one label per tweet. Your input is the pandas data frame `data`. Your output should be a data frame of 1000 rows, with one `emotion` field for each `tweet_id`. You should use the Majority Decision algorithm, where the value of `emotion` field is simply the one occurring most frequently per `tweet_id`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We're only interested in these columns for now ['tweet_id','emotion', 'tweet_body'].\n",
    "# We convert the data to an object with just these columns \n",
    "data= data[['tweet_id','emotion', 'tweet_body']]\n",
    "\n",
    "# TODO: Next we group the data with here\n",
    "agg_data = data..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, your data should have been aggregated. You should get 1000 rows in total as we had 20 labels. The index column for your data frame would be the `tweet_id`. Let's get a preview of how the data frame looks like now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can verify the shape of the resulting data (should be (1000,2))\n",
    "print('data shape:',agg_data.shape)\n",
    "# We can also check the columns and the index\n",
    "print('data columns:',agg_data.columns)\n",
    "print('data columns:',agg_data.index.name)\n",
    "agg_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split now the dataset into two parts, the training data and the testing data. The test data should be 0.2 of the original data size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: fill here\n",
    "train_data, test_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check a sample of the training data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check a sample of the test data\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the number of samples from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('training') \n",
    "print(train_data.emotion.value_counts())\n",
    "print('testing')\n",
    "print(test_data.emotion.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Feature Creation\n",
    "\n",
    "Now that we have aggregated the data, we will work on creating the features to use in our classifier. The input to the classifier is a tweet. However, for this task, we will be using the tokens (e.g., words) in the tweet as the feautres.\n",
    "In specific, each tweet will be represented with a vector that indicates what words are in the tweet and how frequently each word occurs. This way, we do not account for the order of occurrence of these words. This kind of features is also called the **bag of words** technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further process and take a look first on our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train_data['tweet_body'].values\n",
    "y_train = train_data['emotion'].values\n",
    "x_test = test_data['tweet_body'].values\n",
    "y_test = test_data['emotion'].values\n",
    "\n",
    "print(list(zip(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we can transform our tweets into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "# we take two samples\n",
    "samples = x_train[:2]\n",
    "# TODO: fit and transform these samples to get the count vectors\n",
    "x_train_counts = ...\n",
    "\n",
    "# You can see how these vectors look with the following commands\n",
    "print(pd.DataFrame(x_train_counts.A, columns=count_vect.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Creating the Classifiers\n",
    "\n",
    "In practice, it's cleaner to integrate all of our preprocessing and classifier into a single [pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). So let's do that now. Add the missing code to build a simple pipeline with CountVectorizer and a Multinomial Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "def build_pipeline(classifier_fn,x_train,y_train):\n",
    "    pipeline = Pipeline([\n",
    "        # TODO: add the missing code here\n",
    "        ('count_vectorizer',  ...,\n",
    "        ('classifier',          ...)\n",
    "        ])\n",
    "    pipeline.fit(x_train,y_train)\n",
    "    return pipeline\n",
    "\n",
    "pipeline = build_pipeline(MultinomialNB(),x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the classifiers, we will be using the precision, recall, and F1 scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support,classification_report, confusion_matrix\n",
    "\n",
    "# TODO: get the class names from the data\n",
    "class_names = ...\n",
    "\n",
    "def plot_confusion_matrix(y_test,y_predicted,labels):\n",
    "    cm = confusion_matrix(y_test, y_predicted,labels =labels)\n",
    "\n",
    "    figsize = (10,7)\n",
    "    df_cm = pd.DataFrame(\n",
    "        cm, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    return\n",
    "    \n",
    "def evaluate_classifier(pipeline, x_test, y_test):\n",
    "    # TODO: get the predictions\n",
    "    y_predicted = ...\n",
    "    # TODO: generate the report\n",
    "    report  = ...\n",
    "    print(report)\n",
    "    # TODO: plot the confusion matrix\n",
    "    ...\n",
    "    return\n",
    "\n",
    "evaluate_classifier(pipeline, x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can experiment with other classifiers as we please at this point. Try using an SVM classifier and a RandomForestClassifier classifier instead. You might notice that the Multinomial Naive Bayes is already a good baseline for short text classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# TODO: build the pipeline with an SGDClassifier (SVM) and evaluate it\n",
    "...\n",
    "...\n",
    "\n",
    "\n",
    "# TODO: build the pipeline with a Random Forest Classifier and evaluate it\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Predicting Emotions for New Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that as have the classifiers, we can try them a couple of new tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = [\"love the weather\",\"#WEATHER: 7:51 am E: 55.0F. Feels F. 30.01% Humidity. 3.5MPH Variable Wind.\"]\n",
    "# TODO: get the predictions\n",
    "predictions = ...\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Visualizing a Decision Tree Classifier\n",
    "\n",
    "side note: this requires the installation of **graphviz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to see how our features are affecting the classification is to use interpretable classifiers like Decision Trees. To begin with, let's add another step to our pipeline, where we use TF-IDF measure for each word as a vector element instead of taking the term frequency only. We'll use the [TfidfTransformer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# TODO: build a new pipeline with the TfidfTransformer\n",
    "def build_pipeline(classifier_fn,x_train,y_train):\n",
    "    pipeline = Pipeline([\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "        ])\n",
    "    pipeline.fit(x_train,y_train)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to build and visualize the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# TODO: build the pipeline with the Decision Tree Classifier\n",
    "pipeline =...\n",
    "# extract the classifier and the count_vectorizer from the pipeline\n",
    "classifier= pipeline.get_params()['classifier']\n",
    "count_vectorizer = pipeline.get_params()['count_vectorizer']\n",
    "# TODO: Use export_graphviz to visualize the classifiers. You already have all the needed parameters.\n",
    "dot_data = ...\n",
    "\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 Get Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to debug our classifiers and see how they are working is to investigate the features and print the most important ones. We'll do that next. But to start, let's do one more preprocessing step that further removes some of the noise: removing stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# remove stopwords in order to improve interpretability\n",
    "stop = stopwords.words('english')\n",
    "stop += ['rt','@mention:','@mention','link']\n",
    "\n",
    "# TODO: write a function that removes the stop words from each string in a numpy array of strings \n",
    "def remove_stopwords(x_train):\n",
    "    ...\n",
    "\n",
    "\n",
    "x_train_nostop = remove_stopwords(x_train)\n",
    "x_test_no_stop = remove_stopwords(x_test)\n",
    "\n",
    "print(x_train_nostop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to get the most important features for each class. Complete the function below with the missing lines. An easy sanity check is to see if the words that are important for the \"Positive\" class are actually positive and vice-versa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_informative_feature_for_class(vectorizer, classifier, classlabel, n=20):\n",
    "    labelid = list(classifier.classes_).index(classlabel)\n",
    "    # TODO: get the feature names from the vectorizer\n",
    "    feature_names = ...\n",
    "    topn = sorted(zip(classifier.coef_[labelid], feature_names))[-n:]\n",
    "\n",
    "    for coef, feat in topn:\n",
    "        print(classlabel, feat, coef)\n",
    "\n",
    "        \n",
    "pipeline = build_pipeline(MultinomialNB(),x_train_nostop,y_train)\n",
    "# TODO: get the most informative features for a Multinomial NB classifier \n",
    "# by using the function above for the classes \"Positive\" and \"Negative\"\n",
    "classifier= ...\n",
    "count_vectorizer = ...\n",
    "most_informative_feature_for_class(count_vectorizer,classifier,\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_informative_feature_for_class(count_vectorizer, classifier, \"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_informative_feature_for_class(count_vectorizer, classifier, \"Neutral / author is just sharing information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we were using a training set and a testing set for evaluating our models. A more robust way to evaluate a model is to use cross validation. In the code below, we will do such evaluation. At the same time, we will use the cross-validation results to select better parameters for our model. More specifically, we will find a good `alpha` parameter for the `MultinomialNB` model. Hence, we will plot the variation of the F1 score for the \"Positive\" and the \"Negative\" labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "# construct a new X and y \n",
    "X = np.concatenate((x_train_nostop, x_test_no_stop),axis=0)\n",
    "y = np.concatenate((y_train, y_test),axis=0)  \n",
    "\n",
    "# prepare for the cross validation \n",
    "kf = StratifiedKFold(n_splits=5,random_state=4)\n",
    "\n",
    "alphas = [(i*0.1) for i in range(0,10)]\n",
    "\n",
    "\n",
    "total_f1_pos = []\n",
    "total_f1_neg = []\n",
    "\n",
    "for a in alphas:\n",
    "    f_score_pos = []\n",
    "    f_score_neg = []\n",
    "    for train_index, test_index in kf.split(X,y):\n",
    "        \n",
    "        # TODO: build the pipeline for the current alpha and the current training and testing set \n",
    "        pipeline = ...\n",
    "       \n",
    "        y_predicted = pipeline.predict(X[test_index])\n",
    "        report  = precision_recall_fscore_support(y[test_index], y_predicted)\n",
    "        \n",
    "        # let's get the f1_score value for the \"Positive\" and the \"Negative\" labels to plot them\n",
    "        \n",
    "        ind_pos = list(pipeline.classes_).index('Positive')\n",
    "        ind_neg = list(pipeline.classes_).index('Negative')\n",
    "\n",
    "        # report 0 is precision\n",
    "        # report 2 is f-score\n",
    "        fscore_positive = report[0][ind_pos]\n",
    "        fscore_negative = report[0][ind_neg]\n",
    "        \n",
    "        f_score_pos += [fscore_positive]\n",
    "        f_score_neg += [fscore_negative]\n",
    "    # TODO: extend the arrays with the average  fscore_positive and fscore_negative repsectively.\n",
    "    total_f1_pos += ...\n",
    "    total_f1_neg += ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the variation of the F1 score with different `alpha` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(alphas,total_f1_pos,label='Positive')\n",
    "plt.plot(alphas,total_f1_neg,label='Negative')\n",
    "\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task 9: Food for thought\n",
    "\n",
    "There is a lot of room for improvement in the above problem. Here are some issues to think about:\n",
    "- You can see a lot of numbers and measures of wind speed or humidity in the dataset. Can we do some custom tokenization to group these similar features into a single one?\n",
    "- Can we alternatively discretize these measures and turn them into discrete features like low/high wind speed? If people are expressing sentiment based on temperature, humdity, etc., this could be a good potential classifier which can work well in practice.\n",
    "- You have seen that some of the labels have no predictions in the testing set. This is due to the imbalanced dataset. What can we do to improve this?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
